{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3294e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f392e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pdf2image import convert_from_path\n",
    "import base64\n",
    "import io\n",
    "import os\n",
    "\n",
    "# Replace with your OpenAI API key\n",
    "#openai.api_key = 'your-api-key'\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=<ADD_YOUR_API_KEY>,\n",
    ")\n",
    "\n",
    "\n",
    "frmt=open('icon_format_last.txt','r').read()\n",
    "\n",
    "# Step 1: Take input of a PDF path\n",
    "data_path = input(\"Enter the path to the folder: \")\n",
    "pdf_path = data_path + '/pdfs'\n",
    "op_path = data_path + '/op'\n",
    "opjson_path = data_path + '/op_JSON'\n",
    "\n",
    "for ip_pdf in os.listdir(pdf_path):\n",
    "    if not ip_pdf.endswith(\".pdf\"):\n",
    "        continue\n",
    "    op_file = os.path.join(op_path, f\"{os.path.splitext(ip_pdf)[0]}.txt\")\n",
    "    opjson_file = os.path.join(opjson_path, f\"{os.path.splitext(ip_pdf)[0]}.json\")\n",
    "\n",
    "    #print(os.path.join(pdf_path,ip_pdf))\n",
    "    #print(op_file)\n",
    "    # Step 2: Convert PDF pages to images in memory\n",
    "    images = convert_from_path(os.path.join(pdf_path,ip_pdf))\n",
    "    # Initialize the conversation context\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI model that can extract the meaning of images.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Extract the key-values of the page-wise images of a PDF (genomic report). I will give the images (pages) soon one by one.\"}\n",
    "    ]\n",
    "    meaning=''\n",
    "\n",
    "    # Step 3: Send the initial prompt\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        max_tokens= 4000,\n",
    "        temperature= 0.2\n",
    "    )\n",
    "    \n",
    "    # Extract and print the initial response from the assistant\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "    # Step 4: Iteratively process each page image and send it to OpenAI\n",
    "    for i, image in enumerate(images):\n",
    "        # Convert the image to bytes in memory\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        image.save(img_byte_arr, format='JPEG')\n",
    "        img_byte_arr = img_byte_arr.getvalue()\n",
    "    \n",
    "        # Encode the image to base64 directly from memory\n",
    "        encoded_string = base64.b64encode(img_byte_arr).decode('utf-8')\n",
    "        \n",
    "        # Send a message including the encoded image\n",
    "        #messages.append({\"role\": \"user\", \"content\": f\"This is page {i + 1} of the PDF: {encoded_string}\"})\n",
    "        messages.append({\"role\": \"user\", \n",
    "        \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": f\"This is page {i + 1} of the PDF: \"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{encoded_string}\"\n",
    "                    }\n",
    "                }\n",
    "                ]})\n",
    "    \n",
    "        # Send the updated conversation to OpenAI\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            max_tokens= 4000,\n",
    "            temperature= 0.2\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Extract and print the assistant's response\n",
    "        assistant_reply = response.choices[0].message.content\n",
    "        print(f\"Meaning extracted for Page {i + 1}: {assistant_reply}\")\n",
    "        meaning= meaning + assistant_reply\n",
    "        \n",
    "        # Append the assistant's response to the message history\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "        \n",
    "    \n",
    "      \n",
    "\n",
    "    messages2 = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI model that can understand information extracted from a Genomic report.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Read the genomic report summary and structure the output according to the specified format given below.\"}\n",
    "    ]\n",
    "    messages2.append({\"role\": \"user\", \n",
    "        \"content\":[\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Summary of the Genomic report: \" + meaning\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"The response format: \" + frmt\n",
    "                }\n",
    "    ]})\n",
    "\n",
    "    response2 = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages2,\n",
    "            max_tokens= 4000,\n",
    "            temperature= 0.2\n",
    "        )\n",
    "    \n",
    "    open(op_file, 'w').write(response2.choices[0].message.content)\n",
    "    oplist= response2.choices[0].message.content\n",
    "    messages3 = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI model that can convert a hierarchical list of key:value to a JSON file.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hierarchical list: \" + oplist}\n",
    "    ]\n",
    "    \n",
    "    response3 = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages3,\n",
    "            max_tokens= 4000,\n",
    "            temperature= 0.2\n",
    "        )\n",
    "    open(opjson_file, 'w').write(response3.choices[0].message.content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    messages3 = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI model that can convert a hierarchical list of key:value to a JSON file.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Read the genomic report summary and structure the output according to the specified format given below.\"}\n",
    "    ]\n",
    "    messages2.append({\"role\": \"user\", \n",
    "        \"content\":\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Hierarchical list: \" + response2.choices[0].message.content\n",
    "                }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f2e8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9b4112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def parse_hierarchical_list(file_path):\n",
    "    data = {}\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            \n",
    "            # Ignore lines starting with '###' or numerical labels\n",
    "            if line.startswith('###'):\n",
    "                continue\n",
    "            \n",
    "            # Use regex to capture key-value pairs and strip leading labels like '1.1', '1.2'\n",
    "            match = re.match(r'\\d+\\.\\d+ (.*?): (.*)', line)\n",
    "            if match:\n",
    "                key = match.group(1).strip()\n",
    "                value = match.group(2).strip()\n",
    "                data[key] = value\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_as_json(data, json_file_path):\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "# Input file path\n",
    "input_file = ''\n",
    "\n",
    "# Parse the hierarchical list to dictionary\n",
    "parsed_data = parse_hierarchical_list(input_file)\n",
    "\n",
    "# Output JSON file path\n",
    "output_file = 'doc2_1.json'\n",
    "\n",
    "# Save the parsed data as JSON\n",
    "save_as_json(parsed_data, output_file)\n",
    "\n",
    "print(f\"Hierarchical list has been converted to JSON and saved as '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c2d396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
